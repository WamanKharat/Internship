{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e8e0ffc9",
   "metadata": {},
   "source": [
    "Q1: Write a python program to scrape data for “Data Analyst” Job position in “Bangalore” location. You\n",
    "have to scrape the job-title, job-location, company_name, experience_required. You have to scrape first 10\n",
    "jobs data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b573407f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: selenium in c:\\users\\pc\\anaconda3\\lib\\site-packages (4.5.0)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from selenium) (2021.10.8)\n",
      "Requirement already satisfied: trio~=0.17 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from selenium) (0.22.0)\n",
      "Requirement already satisfied: urllib3[socks]~=1.26 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from selenium) (1.26.7)\n",
      "Requirement already satisfied: trio-websocket~=0.9 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from selenium) (0.9.2)\n",
      "Requirement already satisfied: sortedcontainers in c:\\users\\pc\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (2.4.0)\n",
      "Requirement already satisfied: async-generator>=1.9 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.10)\n",
      "Requirement already satisfied: cffi>=1.14 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.14.6)\n",
      "Requirement already satisfied: idna in c:\\users\\pc\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (3.2)\n",
      "Requirement already satisfied: attrs>=19.2.0 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (21.2.0)\n",
      "Requirement already satisfied: sniffio in c:\\users\\pc\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.2.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.0rc9 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.0.0rc9)\n",
      "Requirement already satisfied: outcome in c:\\users\\pc\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.2.0)\n",
      "Requirement already satisfied: pycparser in c:\\users\\pc\\anaconda3\\lib\\site-packages (from cffi>=1.14->trio~=0.17->selenium) (2.20)\n",
      "Requirement already satisfied: wsproto>=0.14 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from trio-websocket~=0.9->selenium) (1.2.0)\n",
      "Requirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from urllib3[socks]~=1.26->selenium) (1.7.1)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "43d7fb73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from selenium.common.exceptions import StaleElementReferenceException, NoSuchElementException\n",
    "from selenium.webdriver.common.by import By\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed7d456e",
   "metadata": {},
   "source": [
    "Now we will download for the web driver for the web browser.steps for download are \n",
    "1.check the version of your browser\n",
    "2.go to the link hhtps://chromedriver.chromium.org/downloads\n",
    "3.download the webdriver for your version of your browser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "59261c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Les first connect to the driver\n",
    "driver=webdriver.Chrome(r'E:\\Datatrained\\chromedriver_win32\\chromedriver.exe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "06e32255",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opening the naukri page on automated chrome browser\n",
    "driver.get(\"https://www.naukri.com\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bb0dfdff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# entering designation and location as required\n",
    "designation=driver.find_element(By.CLASS_NAME,\"suggestor-input\")\n",
    "designation.send_keys(\"Data Analyst\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c03bc3f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "location=driver.find_element(By.XPATH,\"/html/body/div[1]/div[6]/div/div/div[5]/div/div/div/input\")\n",
    "location.send_keys('Bangalore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c2097684",
   "metadata": {},
   "outputs": [],
   "source": [
    "search=driver.find_element(By.CLASS_NAME,\"qsbSubmit\")\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bd39724c",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_title=[]\n",
    "job_location=[]\n",
    "company_name=[]\n",
    "experience_required=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b0a66c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scraping job title from the given page\n",
    "title_tags=driver.find_elements(By.XPATH,\"//a[@class='title fw500 ellipsis']\")\n",
    "for i in title_tags[0:10]:\n",
    "    title=i.text\n",
    "    job_title.append(title)\n",
    "\n",
    "# Scraping job location from the given page\n",
    "location_tags=driver.find_elements(By.XPATH,\"//li[@class='fleft grey-text br2 placeHolderLi location']\")\n",
    "for i in location_tags[0:10]:\n",
    "    location=i.text\n",
    "    job_location.append(location)\n",
    "    \n",
    "#scraping company name from the given page\n",
    "company_tags=driver.find_elements(By.XPATH,\"//a[@class='subTitle ellipsis fleft']\")\n",
    "for i in company_tags[0:10]:\n",
    "    company=i.text\n",
    "    company_name.append(company)\n",
    "    \n",
    "#scraping job experience from the given page\n",
    "experience_tags=driver.find_elements(By.XPATH,\"//li[@class='fleft grey-text br2 placeHolderLi experience']//span\")\n",
    "for i in experience_tags[0:10]:\n",
    "    exp=i.text\n",
    "    experience_required.append(exp)\n",
    "                                     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "de17e952",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 10 10\n"
     ]
    }
   ],
   "source": [
    "print(len(job_title),len(job_location),len(company_name),len(experience_required))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2993687d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job_Title</th>\n",
       "      <th>Job_Location</th>\n",
       "      <th>Company_Name</th>\n",
       "      <th>Exp_Required</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Senior Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru, Chennai</td>\n",
       "      <td>Latentview</td>\n",
       "      <td>3-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru, Mangaluru/Mangalore, Pune...</td>\n",
       "      <td>Coresight Research, Inc.</td>\n",
       "      <td>4-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Varite</td>\n",
       "      <td>2-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Analyst - CRM Platform</td>\n",
       "      <td>Bangalore/Bengaluru, Mumbai, Hyderabad/Secunde...</td>\n",
       "      <td>Artech infosystem</td>\n",
       "      <td>1-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Jar</td>\n",
       "      <td>0-4 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Hiring For Data Analyst (DA)/ Team Lead (TL) -...</td>\n",
       "      <td>Bangalore/Bengaluru, Kolkata, Hyderabad/Secund...</td>\n",
       "      <td>Cognizant</td>\n",
       "      <td>3-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Call For Clinical Data Analyst - Hyd/Bangalore...</td>\n",
       "      <td>Bangalore/Bengaluru, Kolkata, Hyderabad/Secund...</td>\n",
       "      <td>Cognizant</td>\n",
       "      <td>6-9 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Payroll Transformation Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Arrow Electronics</td>\n",
       "      <td>5-10 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Payroll Transformation Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Arrow Electronics</td>\n",
       "      <td>3-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Master Data Management Business Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Accenture</td>\n",
       "      <td>6-8 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Job_Title  \\\n",
       "0                                Senior Data Analyst   \n",
       "1                                       Data Analyst   \n",
       "2                                       Data Analyst   \n",
       "3                        Data Analyst - CRM Platform   \n",
       "4                                       Data Analyst   \n",
       "5  Hiring For Data Analyst (DA)/ Team Lead (TL) -...   \n",
       "6  Call For Clinical Data Analyst - Hyd/Bangalore...   \n",
       "7                Payroll Transformation Data Analyst   \n",
       "8                Payroll Transformation Data Analyst   \n",
       "9            Master Data Management Business Analyst   \n",
       "\n",
       "                                        Job_Location  \\\n",
       "0                       Bangalore/Bengaluru, Chennai   \n",
       "1  Bangalore/Bengaluru, Mangaluru/Mangalore, Pune...   \n",
       "2                                Bangalore/Bengaluru   \n",
       "3  Bangalore/Bengaluru, Mumbai, Hyderabad/Secunde...   \n",
       "4                                Bangalore/Bengaluru   \n",
       "5  Bangalore/Bengaluru, Kolkata, Hyderabad/Secund...   \n",
       "6  Bangalore/Bengaluru, Kolkata, Hyderabad/Secund...   \n",
       "7                                Bangalore/Bengaluru   \n",
       "8                                Bangalore/Bengaluru   \n",
       "9                                Bangalore/Bengaluru   \n",
       "\n",
       "               Company_Name Exp_Required  \n",
       "0                Latentview      3-6 Yrs  \n",
       "1  Coresight Research, Inc.      4-8 Yrs  \n",
       "2                    Varite      2-5 Yrs  \n",
       "3         Artech infosystem      1-6 Yrs  \n",
       "4                       Jar      0-4 Yrs  \n",
       "5                 Cognizant      3-8 Yrs  \n",
       "6                 Cognizant      6-9 Yrs  \n",
       "7         Arrow Electronics     5-10 Yrs  \n",
       "8         Arrow Electronics      3-7 Yrs  \n",
       "9                 Accenture      6-8 Yrs  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating dataframe from above data\n",
    "df=pd.DataFrame({'Job_Title':job_title,'Job_Location':job_location,'Company_Name':company_name,'Exp_Required':experience_required})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dd92519",
   "metadata": {},
   "source": [
    "Q2: Write a python program to scrape data for “Data Scientist” Job position in “Bangalore” location. You have to scrape the job-title, job-location, company_name. You have to scrape first 10 jobs data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "946747d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Les first connect to the driver\n",
    "driver=webdriver.Chrome(r'E:\\Datatrained\\chromedriver_win32\\chromedriver.exe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c9d5daf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opening the naukri page on automated chrome browser\n",
    "driver.get(\"https://www.naukri.com\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8d08bd73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# entering designation and location as required\n",
    "designation=driver.find_element(By.CLASS_NAME,\"suggestor-input\")\n",
    "designation.send_keys(\"Data Scientist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c73b6e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "location=driver.find_element(By.XPATH,\"/html/body/div[1]/div[6]/div/div/div[5]/div/div/div/input\")\n",
    "location.send_keys('Bangalore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0d69ea19",
   "metadata": {},
   "outputs": [],
   "source": [
    "search=driver.find_element(By.CLASS_NAME,\"qsbSubmit\")\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "07c3f44f",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_title=[]\n",
    "job_location=[]\n",
    "company_name=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ed6786ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraping job title from the given page\n",
    "title_tags=driver.find_elements(By.XPATH,\"//a[@class='title fw500 ellipsis']\")\n",
    "for i in title_tags[0:10]:\n",
    "    title=i.text\n",
    "    job_title.append(title)\n",
    "\n",
    "# Scraping job location from the given page\n",
    "location_tags=driver.find_elements(By.XPATH,\"//li[@class='fleft grey-text br2 placeHolderLi location']\")\n",
    "for i in location_tags[0:10]:\n",
    "    location=i.text\n",
    "    job_location.append(location)\n",
    "    \n",
    "#scraping company name from the given page\n",
    "company_tags=driver.find_elements(By.XPATH,\"//a[@class='subTitle ellipsis fleft']\")\n",
    "for i in company_tags[0:10]:\n",
    "    company=i.text\n",
    "    company_name.append(company)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b1ad9bbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 10\n"
     ]
    }
   ],
   "source": [
    "print(len(job_title),len(job_location),len(company_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "929c8d52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job_Title</th>\n",
       "      <th>Job_Location</th>\n",
       "      <th>Company_Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Science Specialist</td>\n",
       "      <td>Bangalore/Bengaluru, Kolkata, Mumbai, Hyderaba...</td>\n",
       "      <td>Accenture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Science Manager</td>\n",
       "      <td>Bangalore/Bengaluru, Kolkata, Mumbai, Hyderaba...</td>\n",
       "      <td>Accenture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mongodb Database Administrator, Maria DB or Ca...</td>\n",
       "      <td>Bangalore/Bengaluru, Hyderabad/Secunderabad, P...</td>\n",
       "      <td>Mphasis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Assistant Manager - Data Science</td>\n",
       "      <td>Bangalore/Bengaluru, Mumbai, Pune</td>\n",
       "      <td>CitiusTech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru, New Delhi, Pune, Gurgaon/...</td>\n",
       "      <td>ZS Associates</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru, Hyderabad/Secunderabad, P...</td>\n",
       "      <td>Tech Mahindra</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru, Mumbai, New Delhi, Chennai</td>\n",
       "      <td>Boston Consulting Group</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Scientist: Artificial Intelligence</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>IBM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data Scientist - Computer Vision</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Walmart</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru, Pune, Chennai</td>\n",
       "      <td>Wipro</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Job_Title  \\\n",
       "0                            Data Science Specialist   \n",
       "1                               Data Science Manager   \n",
       "2  Mongodb Database Administrator, Maria DB or Ca...   \n",
       "3                   Assistant Manager - Data Science   \n",
       "4                                     Data Scientist   \n",
       "5                                     Data Scientist   \n",
       "6                              Senior Data Scientist   \n",
       "7            Data Scientist: Artificial Intelligence   \n",
       "8                   Data Scientist - Computer Vision   \n",
       "9                              Senior Data Scientist   \n",
       "\n",
       "                                        Job_Location             Company_Name  \n",
       "0  Bangalore/Bengaluru, Kolkata, Mumbai, Hyderaba...                Accenture  \n",
       "1  Bangalore/Bengaluru, Kolkata, Mumbai, Hyderaba...                Accenture  \n",
       "2  Bangalore/Bengaluru, Hyderabad/Secunderabad, P...                  Mphasis  \n",
       "3                  Bangalore/Bengaluru, Mumbai, Pune               CitiusTech  \n",
       "4  Bangalore/Bengaluru, New Delhi, Pune, Gurgaon/...            ZS Associates  \n",
       "5  Bangalore/Bengaluru, Hyderabad/Secunderabad, P...            Tech Mahindra  \n",
       "6    Bangalore/Bengaluru, Mumbai, New Delhi, Chennai  Boston Consulting Group  \n",
       "7                                Bangalore/Bengaluru                      IBM  \n",
       "8                                Bangalore/Bengaluru                  Walmart  \n",
       "9                 Bangalore/Bengaluru, Pune, Chennai                    Wipro  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating dataframe from above data\n",
    "df=pd.DataFrame({'Job_Title':job_title,'Job_Location':job_location,'Company_Name':company_name})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7037198e",
   "metadata": {},
   "source": [
    "Q3: In this question you have to scrape data using the filters available on the webpage You have to use the location and salary filter. You have to scrape data for “Data Scientist” designation for first 10 job results. You have to scrape the job-title, job-location, company name, experience required. The location filter to be used is “Delhi/NCR”. The salary filter to be used is “3-6” lakhs The task will be done as shown in the below steps:\n",
    "\n",
    "first get the webpage https://www.naukri.com/\n",
    "Enter “Data Scientist” in “Skill, Designations, and Companies” field.\n",
    "Then click the search button.\n",
    "Then apply the location filter and salary filter by checking the respective boxes\n",
    "Then scrape the data for the first 10 jobs results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "86faf0fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Les first connect to the driver\n",
    "driver=webdriver.Chrome(r'E:\\Datatrained\\chromedriver_win32\\chromedriver.exe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5470f523",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opening the naukri page on automated chrome browser\n",
    "driver.get(\"https://www.naukri.com\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b53cf954",
   "metadata": {},
   "outputs": [],
   "source": [
    "# entering designation and location as required\n",
    "designation=driver.find_element(By.CLASS_NAME,\"suggestor-input\")\n",
    "designation.send_keys(\"Data Scientist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8841f677",
   "metadata": {},
   "outputs": [],
   "source": [
    "location=driver.find_element(By.XPATH,\"/html/body/div[1]/div[6]/div/div/div[5]/div/div/div/input\")\n",
    "location.send_keys('Delhi/NCR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6521c2ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "search=driver.find_element(By.CLASS_NAME,\"qsbSubmit\")\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "435322d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_title=[]\n",
    "job_location=[]\n",
    "job_salary=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "abb4cb09",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scraping job title from the given page\n",
    "title_tags=driver.find_elements(By.XPATH,\"//a[@class='title fw500 ellipsis']\")\n",
    "for i in title_tags[0:10]:\n",
    "    title=i.text\n",
    "    job_title.append(title)\n",
    "\n",
    "# Scraping job location from the given page\n",
    "location_tags=driver.find_elements(By.XPATH,\"//li[@class='fleft grey-text br2 placeHolderLi location']\")\n",
    "for i in location_tags[0:10]:\n",
    "    location=i.text\n",
    "    job_location.append(location)\n",
    "\n",
    "#scraping salary from the given page\n",
    "salary_tags=driver.find_elements(By.XPATH,\"//li[@class='fleft grey-text br2 placeHolderLi salary']\")\n",
    "for i in salary_tags[0:10]:\n",
    "    sal=i.text\n",
    "    job_salary.append(sal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d1644acf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 10\n"
     ]
    }
   ],
   "source": [
    "print(len(job_title),len(job_location),len(job_salary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3288647a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job_Title</th>\n",
       "      <th>Job_Location</th>\n",
       "      <th>Job_Salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mongodb Database Administrator, Maria DB or Ca...</td>\n",
       "      <td>Delhi / NCR, Hyderabad/Secunderabad, Pune, Che...</td>\n",
       "      <td>Not disclosed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Delhi / NCR, New Delhi, Pune, Gurgaon/Gurugram...</td>\n",
       "      <td>Not disclosed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>Mumbai, New Delhi, Chennai, Bangalore/Bengaluru</td>\n",
       "      <td>Not disclosed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Delhi / NCR, Noida, Kolkata, Mumbai, Hyderabad...</td>\n",
       "      <td>Not disclosed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Opportunity For Senior Data Scientist/ Busines...</td>\n",
       "      <td>Delhi / NCR, Gurgaon/Gurugram, Bangalore/Benga...</td>\n",
       "      <td>Not disclosed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Exciting opportunity For model monitoring/mode...</td>\n",
       "      <td>Delhi / NCR, New Delhi, Gurgaon/Gurugram, Bang...</td>\n",
       "      <td>Not disclosed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Scientist with Global Service Based Compa...</td>\n",
       "      <td>Delhi / NCR, Kolkata, Pune, Chennai, Bangalore...</td>\n",
       "      <td>25,00,000 - 30,00,000 PA.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Delhi / NCR, Noida, Kolkata, Mumbai, Hyderabad...</td>\n",
       "      <td>Not disclosed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data Scientist - NLP/Python/Spark</td>\n",
       "      <td>Kolkata, Mumbai, Hyderabad/Secunderabad, Pune,...</td>\n",
       "      <td>Not disclosed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data Scientist - Engine Algorithm</td>\n",
       "      <td>Delhi / NCR, Kolkata, Mumbai, Visakhapatnam, H...</td>\n",
       "      <td>Not disclosed</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Job_Title  \\\n",
       "0  Mongodb Database Administrator, Maria DB or Ca...   \n",
       "1                                     Data Scientist   \n",
       "2                              Senior Data Scientist   \n",
       "3                                     Data Scientist   \n",
       "4  Opportunity For Senior Data Scientist/ Busines...   \n",
       "5  Exciting opportunity For model monitoring/mode...   \n",
       "6  Data Scientist with Global Service Based Compa...   \n",
       "7                                     Data Scientist   \n",
       "8                  Data Scientist - NLP/Python/Spark   \n",
       "9                  Data Scientist - Engine Algorithm   \n",
       "\n",
       "                                        Job_Location  \\\n",
       "0  Delhi / NCR, Hyderabad/Secunderabad, Pune, Che...   \n",
       "1  Delhi / NCR, New Delhi, Pune, Gurgaon/Gurugram...   \n",
       "2    Mumbai, New Delhi, Chennai, Bangalore/Bengaluru   \n",
       "3  Delhi / NCR, Noida, Kolkata, Mumbai, Hyderabad...   \n",
       "4  Delhi / NCR, Gurgaon/Gurugram, Bangalore/Benga...   \n",
       "5  Delhi / NCR, New Delhi, Gurgaon/Gurugram, Bang...   \n",
       "6  Delhi / NCR, Kolkata, Pune, Chennai, Bangalore...   \n",
       "7  Delhi / NCR, Noida, Kolkata, Mumbai, Hyderabad...   \n",
       "8  Kolkata, Mumbai, Hyderabad/Secunderabad, Pune,...   \n",
       "9  Delhi / NCR, Kolkata, Mumbai, Visakhapatnam, H...   \n",
       "\n",
       "                  Job_Salary  \n",
       "0              Not disclosed  \n",
       "1              Not disclosed  \n",
       "2              Not disclosed  \n",
       "3              Not disclosed  \n",
       "4              Not disclosed  \n",
       "5              Not disclosed  \n",
       "6  25,00,000 - 30,00,000 PA.  \n",
       "7              Not disclosed  \n",
       "8              Not disclosed  \n",
       "9              Not disclosed  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating dataframe from above data\n",
    "df=pd.DataFrame({'Job_Title':job_title,'Job_Location':job_location,'Job_Salary':job_salary})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74c4b921",
   "metadata": {},
   "source": [
    "Q4: Scrape data of first 100 sunglasses listings on flipkart.com. You have to scrape four attributes:\n",
    "1. Brand\n",
    "2. Product Description\n",
    "3. Price\n",
    "\n",
    "To scrape the data you have to go through following steps:\n",
    "1. Go to Flipkart webpage by url : https://www.flipkart.com/\n",
    "2. Enter “sunglasses” in the search field where “search for products, brands and more” is written and\n",
    "click the search icon\n",
    "3. After that you will reach to the page having a lot of sunglasses. From this page you can scrap the\n",
    "required data as usual."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cd1d8c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Les first connect to the driver\n",
    "driver=webdriver.Chrome(r'E:\\Datatrained\\chromedriver_win32\\chromedriver.exe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "13255b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opening the flipkart page on automated chrome browser\n",
    "driver.get(\"https://www.flipkart.com\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7bc7df14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# entering Brand name of sunglasses required\n",
    "prodct=driver.find_element(By.CLASS_NAME,\"_3704LK\")\n",
    "prodct.send_keys(\"Sunglasses\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ff365406",
   "metadata": {},
   "outputs": [],
   "source": [
    "search=driver.find_element(By.CLASS_NAME,\"L0Z3Pu\")\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fc90b3bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "Brand=[]\n",
    "price=[]\n",
    "discount=[]\n",
    "size=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "40d0e3ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scraping Brand Name from the given page\n",
    "Brand_tags=driver.find_elements(By.XPATH,\"//a[@class='IRpwTa']\")\n",
    "for i in Brand_tags[0:100]:\n",
    "    Name=i.text\n",
    "    Brand.append(Name)\n",
    "\n",
    "#scraping Price of Product from the given page\n",
    "Price_tags=driver.find_elements(By.XPATH,\"//div[@class='_30jeq3']\")\n",
    "for i in Price_tags[0:100]:\n",
    "    rupee=i.text\n",
    "    price.append(rupee)\n",
    "\n",
    "#scraping Discount on product from the given page\n",
    "dis_tags=driver.find_elements(By.XPATH,\"//div[@class='_3Ay6Sb']\")\n",
    "for i in dis_tags[0:100]:\n",
    "    off=i.text\n",
    "    discount.append(off)\n",
    "    \n",
    "#scraping style of product from the given page\n",
    "style_tags=driver.find_elements(By.XPATH,\"//a[@class='IRpwTa']\")\n",
    "for i in style_tags[0:100]:\n",
    "    st=i.text\n",
    "    size.append(st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "64ebff5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120 120 120 120\n"
     ]
    }
   ],
   "source": [
    "print(len(Brand),len(price),len(discount),len(size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1ebe3223",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>Price</th>\n",
       "      <th>Discount</th>\n",
       "      <th>Size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>UV Protection Wayfarer Sunglasses (Free Size)</td>\n",
       "      <td>₹799</td>\n",
       "      <td>20% off</td>\n",
       "      <td>UV Protection Wayfarer Sunglasses (Free Size)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>UV Protection Round Sunglasses (54)</td>\n",
       "      <td>₹179</td>\n",
       "      <td>86% off</td>\n",
       "      <td>UV Protection Round Sunglasses (54)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>UV Protection Wayfarer Sunglasses (Free Size)</td>\n",
       "      <td>₹199</td>\n",
       "      <td>50% off</td>\n",
       "      <td>UV Protection Wayfarer Sunglasses (Free Size)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>UV Protection Oval Sunglasses (Free Size)</td>\n",
       "      <td>₹189</td>\n",
       "      <td>81% off</td>\n",
       "      <td>UV Protection Oval Sunglasses (Free Size)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>UV Protection, Mirrored Wayfarer Sunglasses (54)</td>\n",
       "      <td>₹179</td>\n",
       "      <td>86% off</td>\n",
       "      <td>UV Protection, Mirrored Wayfarer Sunglasses (54)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>Gradient, UV Protection Wayfarer Sunglasses (F...</td>\n",
       "      <td>₹759</td>\n",
       "      <td>15% off</td>\n",
       "      <td>Gradient, UV Protection Wayfarer Sunglasses (F...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>UV Protection Aviator Sunglasses (58)</td>\n",
       "      <td>₹1,039</td>\n",
       "      <td>20% off</td>\n",
       "      <td>UV Protection Aviator Sunglasses (58)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>Mirrored Aviator Sunglasses (55)</td>\n",
       "      <td>₹339</td>\n",
       "      <td>77% off</td>\n",
       "      <td>Mirrored Aviator Sunglasses (55)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>UV Protection, Polarized, Mirrored Rectangular...</td>\n",
       "      <td>₹195</td>\n",
       "      <td>88% off</td>\n",
       "      <td>UV Protection, Polarized, Mirrored Rectangular...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>UV Protection Wayfarer Sunglasses (Free Size)</td>\n",
       "      <td>₹759</td>\n",
       "      <td>15% off</td>\n",
       "      <td>UV Protection Wayfarer Sunglasses (Free Size)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>120 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Brand   Price Discount  \\\n",
       "0        UV Protection Wayfarer Sunglasses (Free Size)    ₹799  20% off   \n",
       "1                  UV Protection Round Sunglasses (54)    ₹179  86% off   \n",
       "2        UV Protection Wayfarer Sunglasses (Free Size)    ₹199  50% off   \n",
       "3            UV Protection Oval Sunglasses (Free Size)    ₹189  81% off   \n",
       "4     UV Protection, Mirrored Wayfarer Sunglasses (54)    ₹179  86% off   \n",
       "..                                                 ...     ...      ...   \n",
       "115  Gradient, UV Protection Wayfarer Sunglasses (F...    ₹759  15% off   \n",
       "116              UV Protection Aviator Sunglasses (58)  ₹1,039  20% off   \n",
       "117                   Mirrored Aviator Sunglasses (55)    ₹339  77% off   \n",
       "118  UV Protection, Polarized, Mirrored Rectangular...    ₹195  88% off   \n",
       "119      UV Protection Wayfarer Sunglasses (Free Size)    ₹759  15% off   \n",
       "\n",
       "                                                  Size  \n",
       "0        UV Protection Wayfarer Sunglasses (Free Size)  \n",
       "1                  UV Protection Round Sunglasses (54)  \n",
       "2        UV Protection Wayfarer Sunglasses (Free Size)  \n",
       "3            UV Protection Oval Sunglasses (Free Size)  \n",
       "4     UV Protection, Mirrored Wayfarer Sunglasses (54)  \n",
       "..                                                 ...  \n",
       "115  Gradient, UV Protection Wayfarer Sunglasses (F...  \n",
       "116              UV Protection Aviator Sunglasses (58)  \n",
       "117                   Mirrored Aviator Sunglasses (55)  \n",
       "118  UV Protection, Polarized, Mirrored Rectangular...  \n",
       "119      UV Protection Wayfarer Sunglasses (Free Size)  \n",
       "\n",
       "[120 rows x 4 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating dataframe from above data\n",
    "df=pd.DataFrame({'Brand':Brand,'Price':price,'Discount':discount,'Size':size})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a18f0fc6",
   "metadata": {},
   "source": [
    "Q5: Scrape 100 reviews data from flipkart.com for iphone11 phone.\n",
    "This task will be done in following steps:\n",
    "1. First get the webpage https://www.flipkart.com/\n",
    "2. Enter “iphone 11” in “Search” field .\n",
    "3. Then click the search button.\n",
    "As shown in the above page you have to scrape the tick marked attributes.These are:\n",
    "1. Rating\n",
    "2. Review summary\n",
    "3. Full review\n",
    "4. You have to scrape this data for first 100 reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0f19462c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Les first connect to the driver\n",
    "driver=webdriver.Chrome(r'E:\\Datatrained\\chromedriver_win32\\chromedriver.exe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4fb2c6fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opening the flipkat page on automated chrome browser\n",
    "driver.get(\"https://www.flipkart.com\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8716a05f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# entering Brand name of iphone11 required\n",
    "prodct=driver.find_element(By.CLASS_NAME,\"_3704LK\")\n",
    "prodct.send_keys(\"iphone11\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0071b98f",
   "metadata": {},
   "outputs": [],
   "source": [
    "search=driver.find_element(By.CLASS_NAME,\"L0Z3Pu\")\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "cb7fd3ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "Review_summary=[]\n",
    "Full_review=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "396a4c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scraping Price of Product from the given page\n",
    "Review_tags=driver.find_elements(By.XPATH,\"//p[@class='_2-N8zT']\")\n",
    "for i in Review_tags:\n",
    "    rup=i.text\n",
    "    Review_summary.append(rup)\n",
    "\n",
    "#scraping Discount on product from the given page\n",
    "Full_tags=driver.find_elements(By.XPATH,\"//div[@class='t-ZTKy']\")\n",
    "for i in Full_tags:\n",
    "    Rw=i.text\n",
    "    Full_review.append(Rw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "55505cd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 100\n"
     ]
    }
   ],
   "source": [
    "print(len(Review_summary),len(Full_review))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "409987c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review_summary</th>\n",
       "      <th>Full_review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Perfect product!</td>\n",
       "      <td>After using 3 years mobile review. Excellent &amp;...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Terrific</td>\n",
       "      <td>I am using the phone for last 5 years and foun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Good phone but not for the power user</td>\n",
       "      <td>Apple's iPhone series have been known for thei...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Super!</td>\n",
       "      <td>This review is after 6 year of purchasing this...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Simply awesome</td>\n",
       "      <td>Really satisfied with the Product I received.....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Don't waste your money</td>\n",
       "      <td>Very bad mic within 2 days my phone mic is not...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Good quality product</td>\n",
       "      <td>impressively Nice......\\nOne of the greatest i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Perfect product!</td>\n",
       "      <td>Nice products thanks flkat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Fabulous!</td>\n",
       "      <td>Fast performance to previous iPhone x\\nGood ca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Mind-blowing purchase</td>\n",
       "      <td>Fantastic and prompt delivery.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Review_summary  \\\n",
       "0                        Perfect product!   \n",
       "1                                Terrific   \n",
       "2   Good phone but not for the power user   \n",
       "3                                  Super!   \n",
       "4                          Simply awesome   \n",
       "..                                    ...   \n",
       "95                 Don't waste your money   \n",
       "96                   Good quality product   \n",
       "97                       Perfect product!   \n",
       "98                              Fabulous!   \n",
       "99                  Mind-blowing purchase   \n",
       "\n",
       "                                          Full_review  \n",
       "0   After using 3 years mobile review. Excellent &...  \n",
       "1   I am using the phone for last 5 years and foun...  \n",
       "2   Apple's iPhone series have been known for thei...  \n",
       "3   This review is after 6 year of purchasing this...  \n",
       "4   Really satisfied with the Product I received.....  \n",
       "..                                                ...  \n",
       "95  Very bad mic within 2 days my phone mic is not...  \n",
       "96  impressively Nice......\\nOne of the greatest i...  \n",
       "97                         Nice products thanks flkat  \n",
       "98  Fast performance to previous iPhone x\\nGood ca...  \n",
       "99                     Fantastic and prompt delivery.  \n",
       "\n",
       "[100 rows x 2 columns]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating dataframe from above data\n",
    "df=pd.DataFrame({'Review_summary':Review_summary,'Full_review':Full_review})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00764eb0",
   "metadata": {},
   "source": [
    "Q6: Scrape data for first 100 sneakers you find when you visit flipkart.com and search for “sneakers” in the\n",
    "search field.\n",
    "You have to scrape 4 attributes of each sneaker:\n",
    "1. Brand\n",
    "2. Product Description\n",
    "3. Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "5b67b754",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Les first connect to the driver\n",
    "driver=webdriver.Chrome(r'E:\\Datatrained\\chromedriver_win32\\chromedriver.exe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "498b056b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opening the flpikart page on automated chrome browser\n",
    "driver.get(\"https://www.flipkart.com\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "e7501f0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# entering Brand name of sneakers required\n",
    "prodct=driver.find_element(By.CLASS_NAME,\"_3704LK\")\n",
    "prodct.send_keys(\"sneakers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "5ab55f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "search=driver.find_element(By.CLASS_NAME,\"L0Z3Pu\")\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "7fb19a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Brand=[]\n",
    "price=[]\n",
    "discount=[]\n",
    "Type=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "bf09f2ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scraping Brand Name from the given page\n",
    "Brand_tags=driver.find_elements(By.XPATH,\"//div[@class='_2WkVRV']\")\n",
    "for i in Brand_tags[0:25]:\n",
    "    Name=i.text\n",
    "    Brand.append(Name)\n",
    "\n",
    "#scraping Price of Product from the given page\n",
    "Price_tags=driver.find_elements(By.XPATH,\"//div[@class='_30jeq3']\")\n",
    "for i in Price_tags[0:25]:\n",
    "    rupee=i.text\n",
    "    price.append(rupee)\n",
    "\n",
    "#scraping Discount on product from the given page\n",
    "dis_tags=driver.find_elements(By.XPATH,\"//div[@class='_3Ay6Sb']\")\n",
    "for i in dis_tags[0:25]:\n",
    "    off=i.text\n",
    "    discount.append(off)\n",
    "    \n",
    "#scraping style of product from the given page\n",
    "style_tags=driver.find_elements(By.XPATH,\"//div[@class='_2B099V']\")\n",
    "for i in style_tags[0:25]:\n",
    "    st=i.text\n",
    "    Type.append(st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "4461f784",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 100 100 100\n"
     ]
    }
   ],
   "source": [
    "print(len(Brand),len(price),len(discount),len(Type))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "1344514d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>Price</th>\n",
       "      <th>Discount</th>\n",
       "      <th>Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RapidBox</td>\n",
       "      <td>₹590</td>\n",
       "      <td>40% off</td>\n",
       "      <td>RapidBox\\nSneakers For Men\\n₹590₹99940% off\\nF...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Shozie</td>\n",
       "      <td>₹479</td>\n",
       "      <td>52% off</td>\n",
       "      <td>Shozie\\nStylish Sneakers Shoes for Men Sneaker...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BRUTON</td>\n",
       "      <td>₹470</td>\n",
       "      <td>63% off</td>\n",
       "      <td>BRUTON\\nModern Trendy Shoes Sneakers For Men\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RED TAPE</td>\n",
       "      <td>₹1,499</td>\n",
       "      <td>70% off</td>\n",
       "      <td>RED TAPE\\nSneakers For Men\\n₹1,499₹4,99970% of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BRUTON</td>\n",
       "      <td>₹259</td>\n",
       "      <td>56% off</td>\n",
       "      <td>BRUTON\\nLightweight Pack Of 1 Trendy Sneakers ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Rzisbo</td>\n",
       "      <td>₹549</td>\n",
       "      <td>45% off</td>\n",
       "      <td>Rzisbo\\nSneakers For Men\\n₹549₹99945% off\\nFre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Kraasa</td>\n",
       "      <td>₹624</td>\n",
       "      <td>37% off</td>\n",
       "      <td>Kraasa\\nCasuals, Canvas, Partywear Sneakers Fo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>BRUTON</td>\n",
       "      <td>₹666</td>\n",
       "      <td>48% off</td>\n",
       "      <td>BRUTON\\nModern Trendy Sneakers Shoes Sneakers ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>MOHLIYE</td>\n",
       "      <td>₹296</td>\n",
       "      <td>57% off</td>\n",
       "      <td>MOHLIYE\\nExclusive Range of Stylish Comfortabl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>BRUTON</td>\n",
       "      <td>₹470</td>\n",
       "      <td>63% off</td>\n",
       "      <td>BRUTON\\nSneaker Sneakers For Men\\n₹470₹1,29963...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Brand   Price Discount  \\\n",
       "0   RapidBox    ₹590  40% off   \n",
       "1     Shozie    ₹479  52% off   \n",
       "2     BRUTON    ₹470  63% off   \n",
       "3   RED TAPE  ₹1,499  70% off   \n",
       "4     BRUTON    ₹259  56% off   \n",
       "..       ...     ...      ...   \n",
       "95    Rzisbo    ₹549  45% off   \n",
       "96    Kraasa    ₹624  37% off   \n",
       "97    BRUTON    ₹666  48% off   \n",
       "98   MOHLIYE    ₹296  57% off   \n",
       "99    BRUTON    ₹470  63% off   \n",
       "\n",
       "                                                 Type  \n",
       "0   RapidBox\\nSneakers For Men\\n₹590₹99940% off\\nF...  \n",
       "1   Shozie\\nStylish Sneakers Shoes for Men Sneaker...  \n",
       "2   BRUTON\\nModern Trendy Shoes Sneakers For Men\\n...  \n",
       "3   RED TAPE\\nSneakers For Men\\n₹1,499₹4,99970% of...  \n",
       "4   BRUTON\\nLightweight Pack Of 1 Trendy Sneakers ...  \n",
       "..                                                ...  \n",
       "95  Rzisbo\\nSneakers For Men\\n₹549₹99945% off\\nFre...  \n",
       "96  Kraasa\\nCasuals, Canvas, Partywear Sneakers Fo...  \n",
       "97  BRUTON\\nModern Trendy Sneakers Shoes Sneakers ...  \n",
       "98  MOHLIYE\\nExclusive Range of Stylish Comfortabl...  \n",
       "99  BRUTON\\nSneaker Sneakers For Men\\n₹470₹1,29963...  \n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating dataframe from above data\n",
    "df=pd.DataFrame({'Brand':Brand,'Price':price,'Discount':discount,'Type':Type})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d62365ef",
   "metadata": {},
   "source": [
    "Q7: Go to the link - https://www.myntra.com/shoes\n",
    "Set second Price filter and Color filter to “Black”, as shown in the below image.\n",
    "And then scrape First 100 shoes data you get. The data should include “Brand” of the shoes , Short Shoe description, price of the shoe as shown in the below image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "3ced9d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Les first connect to the driver\n",
    "driver=webdriver.Chrome(r'E:\\Datatrained\\chromedriver_win32\\chromedriver.exe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "93f6beca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opening the myntra page on automated chrome browser\n",
    "driver.get(\"https://www.myntra.com/shoes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "15652047",
   "metadata": {},
   "outputs": [],
   "source": [
    "Brand=[]\n",
    "price=[]\n",
    "Product_Description=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "5d5ee4eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scraping Brand Name from the given page\n",
    "Brand_tags=driver.find_elements(By.XPATH,\"//h3[@class='product-brand']\")\n",
    "for i in Brand_tags[0:25]:\n",
    "    Name=i.text\n",
    "    Brand.append(Name)\n",
    "\n",
    "#scraping Price of Product from the given page\n",
    "Price_tags=driver.find_elements(By.XPATH,\"//div[@class='product-price']\")\n",
    "for i in Price_tags[0:25]:\n",
    "    rupee=i.text\n",
    "    price.append(rupee)\n",
    "\n",
    "#scraping product description from the given page\n",
    "des_tags=driver.find_elements(By.XPATH,\"//h4[@class='product-product']\")\n",
    "for i in des_tags[0:25]:\n",
    "    prod=i.text\n",
    "    Product_Description.append(prod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "8c487312",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 100 100\n"
     ]
    }
   ],
   "source": [
    "print(len(Brand),len(price),len(Product_Description))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "ac50d45c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>Price</th>\n",
       "      <th>Product_Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>U.S. Polo Assn.</td>\n",
       "      <td>Rs. 1499Rs. 2999(50% OFF)</td>\n",
       "      <td>Men Clarkin Sneakers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Roadster</td>\n",
       "      <td>Rs. 796Rs. 3795(79% OFF)</td>\n",
       "      <td>Men Sneakers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>one8 x PUMA</td>\n",
       "      <td>Rs. 1574Rs. 3499(55% OFF)</td>\n",
       "      <td>Men Alder IDP Running Shoes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bond Street By Red Tape</td>\n",
       "      <td>Rs. 1274Rs. 5099(75% OFF)</td>\n",
       "      <td>Men Colourblocked PU Sneakers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Mactree</td>\n",
       "      <td>Rs. 972Rs. 3890(75% OFF)</td>\n",
       "      <td>Men Colourblocked PU Sneakers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Nike</td>\n",
       "      <td>Rs. 4871Rs. 6495(25% OFF)</td>\n",
       "      <td>Men Run Swift Running Shoes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>HRX by Hrithik Roshan</td>\n",
       "      <td>Rs. 1679Rs. 5599(70% OFF)</td>\n",
       "      <td>Men TR-100 Training Shoe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Reebok</td>\n",
       "      <td>Rs. 1199Rs. 2999(60% OFF)</td>\n",
       "      <td>Men Edgility Running Shoes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>HIGHLANDER</td>\n",
       "      <td>Rs. 796Rs. 1990(60% OFF)</td>\n",
       "      <td>Men Sneakers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>GRIFFIN</td>\n",
       "      <td>Rs. 2399Rs. 3399(Rs. 1000 OFF)</td>\n",
       "      <td>Men Latex Lined Brogues</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Brand                           Price  \\\n",
       "0           U.S. Polo Assn.       Rs. 1499Rs. 2999(50% OFF)   \n",
       "1                  Roadster        Rs. 796Rs. 3795(79% OFF)   \n",
       "2               one8 x PUMA       Rs. 1574Rs. 3499(55% OFF)   \n",
       "3   Bond Street By Red Tape       Rs. 1274Rs. 5099(75% OFF)   \n",
       "4                   Mactree        Rs. 972Rs. 3890(75% OFF)   \n",
       "..                      ...                             ...   \n",
       "95                     Nike       Rs. 4871Rs. 6495(25% OFF)   \n",
       "96    HRX by Hrithik Roshan       Rs. 1679Rs. 5599(70% OFF)   \n",
       "97                   Reebok       Rs. 1199Rs. 2999(60% OFF)   \n",
       "98               HIGHLANDER        Rs. 796Rs. 1990(60% OFF)   \n",
       "99                  GRIFFIN  Rs. 2399Rs. 3399(Rs. 1000 OFF)   \n",
       "\n",
       "              Product_Description  \n",
       "0            Men Clarkin Sneakers  \n",
       "1                    Men Sneakers  \n",
       "2     Men Alder IDP Running Shoes  \n",
       "3   Men Colourblocked PU Sneakers  \n",
       "4   Men Colourblocked PU Sneakers  \n",
       "..                            ...  \n",
       "95    Men Run Swift Running Shoes  \n",
       "96       Men TR-100 Training Shoe  \n",
       "97     Men Edgility Running Shoes  \n",
       "98                   Men Sneakers  \n",
       "99        Men Latex Lined Brogues  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating dataframe from above data\n",
    "df=pd.DataFrame({'Brand':Brand,'Price':price,'Product_Description':Product_Description})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de8f3a86",
   "metadata": {},
   "source": [
    "Q8: Go to webpage https://www.amazon.in/\n",
    "Enter “Laptop” in the search field and then click the search icon.\n",
    "Then set CPU Type filter to “Intel Core i7” as shown in the below image:\n",
    "After setting the filters scrape first 10 laptops data. You have to scrape 3 attributesfor each laptop:\n",
    "1. Title\n",
    "2. Ratings\n",
    "3. Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "61ec7209",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Les first connect to the driver\n",
    "driver=webdriver.Chrome(r'E:\\Datatrained\\chromedriver_win32\\chromedriver.exe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "21aca9ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opening the Amazon page on automated chrome browser\n",
    "driver.get(\"https://www.amazon.in/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "3dba4e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "Title=[]\n",
    "price=[]\n",
    "Ratings=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "42e4cdcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scraping Title of laptop from the given page\n",
    "title_tags=driver.find_elements(By.XPATH,\"//h2[@class='a-size-mini a-spacing-none a-color-base s-line-clamp-2']\")\n",
    "for i in title_tags[0:10]:\n",
    "    Name=i.text\n",
    "    Title.append(Name)\n",
    "\n",
    "#scraping Price of Product from the given page\n",
    "Price_tags=driver.find_elements(By.XPATH,\"//span[@class='a-price-whole']\")\n",
    "for i in Price_tags[0:10]:\n",
    "    rupee=i.text\n",
    "    price.append(rupee)\n",
    "\n",
    "#scraping Ratings on product from the given page\n",
    "Rate_tags=driver.find_elements(By.XPATH,\"//span[@class='a-icon-alt']\")\n",
    "for i in Rate_tags[0:10]:\n",
    "    rat=i.text\n",
    "    Ratings.append(rat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "62076586",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 10\n"
     ]
    }
   ],
   "source": [
    "print(len(Title),len(price),len(Ratings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "a1b4b77e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Price</th>\n",
       "      <th>Ratings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ASUS Vivobook 15, 15.6-inch (39.62 cms) FHD, I...</td>\n",
       "      <td>64,990</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Fujitsu UH-X 11th Gen Intel Core i7 13.3\" FHD ...</td>\n",
       "      <td>1,00,000</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ASUS Zenbook 13 OLED, 13.3-inch (33.78 cms) FH...</td>\n",
       "      <td>93,290</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Lenovo IdeaPad Slim 5 Intel Core i7 12th Gen 1...</td>\n",
       "      <td>79,990</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HP Pavilion x360 11th Gen Intel Core i7 14 inc...</td>\n",
       "      <td>80,990</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ASUS Vivobook 15, 15.6-inch (39.62 cms) FHD, I...</td>\n",
       "      <td>64,990</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Lenovo ThinkBook 15 Intel 11th Gen Core i7 15....</td>\n",
       "      <td>77,990</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>HP Pavilion Plus, 12th Gen Intel Core i7 16GB ...</td>\n",
       "      <td>86,990</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Acer Nitro 5 Core i7 11th Gen 15.6\" (39.62cms)...</td>\n",
       "      <td>89,990</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Lenovo IdeaPad Gaming 3 Intel Core i7-12700H 1...</td>\n",
       "      <td>1,09,990</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title     Price Ratings\n",
       "0  ASUS Vivobook 15, 15.6-inch (39.62 cms) FHD, I...    64,990        \n",
       "1  Fujitsu UH-X 11th Gen Intel Core i7 13.3\" FHD ...  1,00,000        \n",
       "2  ASUS Zenbook 13 OLED, 13.3-inch (33.78 cms) FH...    93,290        \n",
       "3  Lenovo IdeaPad Slim 5 Intel Core i7 12th Gen 1...    79,990        \n",
       "4  HP Pavilion x360 11th Gen Intel Core i7 14 inc...    80,990        \n",
       "5  ASUS Vivobook 15, 15.6-inch (39.62 cms) FHD, I...    64,990        \n",
       "6  Lenovo ThinkBook 15 Intel 11th Gen Core i7 15....    77,990        \n",
       "7  HP Pavilion Plus, 12th Gen Intel Core i7 16GB ...    86,990        \n",
       "8  Acer Nitro 5 Core i7 11th Gen 15.6\" (39.62cms)...    89,990        \n",
       "9  Lenovo IdeaPad Gaming 3 Intel Core i7-12700H 1...  1,09,990        "
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating dataframe from above data\n",
    "df=pd.DataFrame({'Title':Title,'Price':price,'Ratings':Ratings})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3494986",
   "metadata": {},
   "source": [
    "Q10: Write a python program to scrape the salary data for Data Scientist designation.\n",
    "You have to scrape Company name, Number of salaries, Average salary, Minsalary, Max Salary.\n",
    "The above task will be, done as shown in the below steps:\n",
    "1. First get the webpage https://www.ambitionbox.com/\n",
    "2. Click on the salaries option as shown in the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "6d109b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from selenium.common.exceptions import StaleElementReferenceException, NoSuchElementException\n",
    "from selenium.webdriver.common.by import By\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "537be08a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Les first connect to the driver\n",
    "driver=webdriver.Chrome(r'E:\\Datatrained\\chromedriver_win32\\chromedriver.exe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "4edd5669",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opening the Given website page on automated chrome browser\n",
    "driver.get(\"https://www.ambitionbox.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "81ad3dfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "Company_name=[]\n",
    "Experience=[]\n",
    "Minimum_Salary=[]\n",
    "Average_salary=[]\n",
    "Maximum_Salary=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "a8cdf75c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scraping company name from the given page\n",
    "title_tags=driver.find_elements(By.XPATH,\"//div[@class='name']\")\n",
    "for i in title_tags:\n",
    "    Name=i.text\n",
    "    Company_name.append(Name)\n",
    "\n",
    "#Scraping Experience from the given page\n",
    "Exp_tags=driver.find_elements(By.XPATH,\"//div[@class='sbold-list-header']\")\n",
    "for i in Exp_tags:\n",
    "    Expn=i.text\n",
    "    Experience.append(Expn)\n",
    "\n",
    "#Scraping Minimum salary for the job from the given page\n",
    "Min_tags=driver.find_elements(By.XPATH,\"//div[@class='value body-medium']\")\n",
    "for i in Min_tags:\n",
    "    Mini=i.text\n",
    "    Minimum_Salary.append(Mini)\n",
    "    \n",
    "# Scraping Avg Salary from the given page\n",
    "Avg_tags=driver.find_elements(By.XPATH,\"//p[@class='averageCtc']\")\n",
    "for i in Avg_tags:\n",
    "    Avrg=i.text\n",
    "    Average_salary.append(Avrg)\n",
    "    \n",
    "#Scraping Max Salary from the given page\n",
    "Max_tags=driver.find_elements(By.XPATH,\"//div[@class='value body-medium']\")\n",
    "for i in Max_tags:\n",
    "    Maxm=i.text\n",
    "    Maximum_Salary.append(Maxm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "1dac4129",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 0 0 0\n"
     ]
    }
   ],
   "source": [
    "print(len(Company_name),len(Experience),len(Minimum_Salary),len(Average_salary),len(Maximum_Salary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87086788",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
